# ğŸ¨ PokÃ©Guess - Classificador de Sketches de PokÃ©mon

Sistema de reconhecimento de desenhos de PokÃ©mon usando Deep Learning com Transfer Learning. O modelo identifica qual PokÃ©mon foi desenhado e retorna o nome com a confianÃ§a da prediÃ§Ã£o.

![Python](https://img.shields.io/badge/Python-3.11-blue)
![TensorFlow](https://img.shields.io/badge/TensorFlow-2.x-orange)
![Streamlit](https://img.shields.io/badge/Streamlit-1.x-red)

---

## ğŸ“‹ Ãndice

- [VisÃ£o Geral](#visÃ£o-geral)
- [Arquitetura TÃ©cnica](#arquitetura-tÃ©cnica)
- [Dataset](#dataset)
- [Pipeline de Treinamento](#pipeline-de-treinamento)
- [Modelo](#modelo)
- [Data Augmentation](#data-augmentation)
- [InstalaÃ§Ã£o e Uso](#instalaÃ§Ã£o-e-uso)
- [Estrutura do Projeto](#estrutura-do-projeto)
- [Resultados](#resultados)
- [Tecnologias](#tecnologias)
- [Autor](#autor)

---

## ğŸ¯ VisÃ£o Geral

O **PokÃ©Guess** Ã© um sistema de visÃ£o computacional que classifica desenhos (sketches) de PokÃ©mon das geraÃ§Ãµes 1 e 2 (151 + 100 = 251 classes). O usuÃ¡rio desenha um PokÃ©mon em uma interface web e o modelo retorna:

- Nome do PokÃ©mon identificado
- ConfianÃ§a da prediÃ§Ã£o (%)
- Top-K pokÃ©mons mais similares

### CaracterÃ­sticas principais:

- âœ… **Transfer Learning** com MobileNetV2 prÃ©-treinado no ImageNet
- âœ… **251 classes** (PokÃ©mon #001 Bulbasaur atÃ© #251 Celebi)
- âœ… **Data Augmentation** forte para compensar escassez de dados
- âœ… **Fine-tuning em 2 fases** para melhor convergÃªncia
- âœ… **Interface web interativa** com Streamlit
- âœ… **Preprocessing otimizado** para sketches monocromÃ¡ticos

---

## ğŸ—ï¸ Arquitetura TÃ©cnica

### Pipeline Completo

```
Desenho do UsuÃ¡rio (Canvas)
         â†“
  Preprocessing
    - RGBA â†’ Grayscale
    - Resize para 224x224
    - Grayscale â†’ RGB (3 canais)
    - NormalizaÃ§Ã£o [-1, 1]
         â†“
  MobileNetV2 (Feature Extractor)
    - Base congelada (inicialmente)
    - 1280 features extraÃ­das
         â†“
  Classificador Custom
    - Dense(512) + BatchNorm + ReLU + Dropout(0.5)
    - Dense(256) + BatchNorm + ReLU + Dropout(0.4)
    - Dense(251, softmax)
         â†“
  PrediÃ§Ã£o
    - Top-K resultados
    - Confidence scores
```

### DecisÃµes TÃ©cnicas

#### Por que Transfer Learning?

- **Poucos dados**: ~21 imagens por classe (5.271 imagens totais)
- **MobileNetV2 jÃ¡ aprendeu features visuais** Ãºteis do ImageNet
- **ConvergÃªncia mais rÃ¡pida** e melhor generalizaÃ§Ã£o
- **RegularizaÃ§Ã£o implÃ­cita** pela base prÃ©-treinada

#### Por que MobileNetV2?

- **Leve e rÃ¡pido**: 3.5M parÃ¢metros (vs ResNet50 25M)
- **Bom para deployment**: Ideal para aplicaÃ§Ãµes web
- **Depthwise Separable Convolutions**: EficiÃªncia computacional
- **Excelente para imagens 224x224**: Tamanho nativo

---

## ğŸ“Š Dataset

### ComposiÃ§Ã£o

O dataset combina duas fontes:

1. **Synthetic Sketches** (prÃ©-existentes)
   - Sketches sintÃ©ticos gerados de sprites
   - ~9 imagens por PokÃ©mon
   
2. **PokeAPI Sketches** (gerados no notebook)
   - Sprites oficiais da PokeAPI
   - Convertidos para sketch usando 3 mÃ©todos:
     - **Canny Edge Detection**: Bordas nÃ­tidas
     - **Pencil Sketch**: Estilo lÃ¡pis
     - **Laplacian**: DetecÃ§Ã£o de gradientes
   - 5 sprites Ã— 3 mÃ©todos = 15 imagens por PokÃ©mon

### Processamento de Imagens da PokeAPI

```python
def image_to_sketch(image, method='canny'):
    # Canny: Blur + Edge Detection
    blurred = cv2.GaussianBlur(gray, (3, 3), 0)
    edges = cv2.Canny(blurred, 30, 100)
    sketch = 255 - edges  # Inverter: linhas pretas em fundo branco
```

### EstatÃ­sticas do Dataset

- **Total de classes**: 251 PokÃ©mon
- **Total de imagens**: ~5.271
- **MÃ©dia por classe**: ~21 imagens
- **Split**: 80% treino / 10% validaÃ§Ã£o / 10% teste
- **Formato**: PNG, fundo branco, linhas pretas

---

## ğŸ”„ Pipeline de Treinamento

### Fase 1: Treinamento do Classificador (Base Congelada)

```python
# Congelar base do MobileNetV2
base_model.trainable = False

# Compilar
model.compile(
    optimizer=Adam(lr=0.001),
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

# Treinar (30 Ã©pocas)
history1 = model.fit(train_generator, ...)
```

**Objetivo**: Treinar o classificador custom sem alterar os pesos da base prÃ©-treinada.

### Fase 2: Fine-Tuning (Ãšltimas 30 Camadas Descongeladas)

```python
# Descongelar Ãºltimas 30 camadas
base_model.trainable = True
for layer in base_model.layers[:-30]:
    layer.trainable = False

# Recompilar com LR muito menor
model.compile(
    optimizer=Adam(lr=1e-5),  # 100x menor!
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

# Treinar (50 Ã©pocas)
history2 = model.fit(train_generator, ...)
```

**Objetivo**: Ajustar finamente as Ãºltimas camadas da base para adaptar Ã s caracterÃ­sticas dos sketches.

### Callbacks Utilizados

```python
callbacks = [
    EarlyStopping(
        monitor='val_accuracy',
        patience=15,
        mode='max'
    ),
    ReduceLROnPlateau(
        monitor='val_accuracy',
        factor=0.5,
        patience=7,
        mode='max'
    ),
    ModelCheckpoint(
        'best_model.keras',
        monitor='val_accuracy',
        save_best_only=True
    )
]
```

---

## ğŸ¤– Modelo

### Arquitetura Detalhada

```python
Input (224, 224, 3)
    â†“
MobileNetV2 Base (weights='imagenet', pooling='avg')
    - 1280 features
    â†“
Dense(512) + L2(0.01)
    â†“
BatchNormalization
    â†“
ReLU
    â†“
Dropout(0.5)
    â†“
Dense(256) + L2(0.01)
    â†“
BatchNormalization
    â†“
ReLU
    â†“
Dropout(0.4)
    â†“
Dense(251, activation='softmax')
```

### ParÃ¢metros do Modelo

- **Total de parÃ¢metros**: ~3.7M
- **TreinÃ¡veis (Fase 1)**: ~850K (apenas classificador)
- **TreinÃ¡veis (Fase 2)**: ~1.5M (classificador + Ãºltimas 30 camadas)
- **Congelados**: ~2.2M (maior parte do MobileNetV2)

### RegularizaÃ§Ã£o

- **L2 Regularization** (0.01) nas camadas Dense
- **Dropout** (0.5 e 0.4) para prevenir overfitting
- **BatchNormalization** para estabilizar treinamento
- **Data Augmentation** (ver prÃ³xima seÃ§Ã£o)

---

## ğŸ”€ Data Augmentation

Para compensar a **escassez de dados** (~21 imagens/classe), aplicamos data augmentation **forte**:

```python
ImageDataGenerator(
    rotation_range=30,           # RotaÃ§Ã£o Â±30Â°
    width_shift_range=0.2,       # Shift horizontal 20%
    height_shift_range=0.2,      # Shift vertical 20%
    shear_range=0.2,             # Shear 20%
    zoom_range=0.2,              # Zoom Â±20%
    horizontal_flip=True,        # Flip horizontal
    vertical_flip=False,         # NÃ£o flip vertical
    brightness_range=[0.8, 1.2], # VariaÃ§Ã£o de brilho
    fill_mode='constant',
    cval=1.0                     # Preencher com branco
)
```

### Justificativa

- **RotaÃ§Ã£o**: Sketches podem ser desenhados em qualquer Ã¢ngulo
- **Shift e Zoom**: Simula diferentes tamanhos e posiÃ§Ãµes
- **Shear**: Adiciona variaÃ§Ã£o geomÃ©trica
- **Brilho**: Compensa diferentes intensidades de traÃ§o
- **No vertical flip**: PokÃ©mon tÃªm orientaÃ§Ã£o definida

---

## ğŸš€ InstalaÃ§Ã£o e Uso

### PrÃ©-requisitos

- Python 3.11+
- pip

### 1. Clonar o RepositÃ³rio

```bash
git clone https://github.com/skaduhs5232/poke_guess.git
cd poke_guess
```

### 2. Instalar DependÃªncias

```bash
pip install -r service/requirements.txt
```

### 3. Treinar o Modelo (Opcional)

Se quiser retreinar o modelo:

```bash
# Abrir o notebook
jupyter notebook notebooks/pokemon_sketch_classifier.ipynb

# Executar todas as cÃ©lulas (Ctrl+A, Shift+Enter)
# Aguardar o treinamento (~30-60 min dependendo do hardware)
```

### 4. Executar a AplicaÃ§Ã£o Web

```bash
streamlit run service/app.py
```

A aplicaÃ§Ã£o abrirÃ¡ em `http://localhost:8501`

### 5. Usar o Modelo

1. Desenhe um PokÃ©mon no canvas
2. Clique em "ğŸ” Identificar PokÃ©mon!"
3. Veja o resultado com confianÃ§a

---

## ğŸ“ Estrutura do Projeto

```
poke_guess/
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ pokemon_sketch_classifier.ipynb  # Notebook principal de treinamento
â”‚   â””â”€â”€ dataset/
â”‚       â”œâ”€â”€ synthetic_sketches/          # Sketches sintÃ©ticos (entrada)
â”‚       â”œâ”€â”€ pokeapi_sketches/            # Sketches gerados da PokeAPI
â”‚       â””â”€â”€ combined/                    # Dataset combinado final
â”‚
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ pokemon_sketch_classifier.keras  # Modelo treinado
â”‚   â”œâ”€â”€ best_model.keras                 # Melhor checkpoint
â”‚   â”œâ”€â”€ label_map.json                   # Mapeamento idx â†” nome
â”‚   â”œâ”€â”€ metrics.json                     # MÃ©tricas de avaliaÃ§Ã£o
â”‚   â””â”€â”€ training_history.png             # GrÃ¡fico de treinamento
â”‚
â”œâ”€â”€ service/
â”‚   â”œâ”€â”€ app.py                           # AplicaÃ§Ã£o Streamlit
â”‚   â””â”€â”€ requirements.txt                 # DependÃªncias
â”‚
â””â”€â”€ README.md                            # Este arquivo
```

---

## ğŸ“ˆ Resultados

### MÃ©tricas de AvaliaÃ§Ã£o

As mÃ©tricas exatas estÃ£o em `model/metrics.json`. Valores esperados:

- **Test Accuracy**: Varia conforme treinamento
- **Top-3 Accuracy**: Geralmente 30-50% maior que Top-1
- **Top-5 Accuracy**: Geralmente 50-70% maior que Top-1

### ConsideraÃ§Ãµes sobre Performance

Com **251 classes** e **~21 imagens por classe**, o modelo enfrenta:

- âœ… **Transfer Learning mitiga overfitting**
- âœ… **Data Augmentation aumenta diversidade**
- âš ï¸ **Poucos dados ainda Ã© um desafio**
- âš ï¸ **PokÃ©mon similares podem confundir** (ex: evoluÃ§Ãµes)

### Melhorias Futuras

Para melhorar o modelo:

1. **Mais dados**: Coletar sketches reais de usuÃ¡rios
2. **Few-Shot Learning**: TÃ©cnicas para classes com poucos exemplos
3. **Ensemble**: Combinar mÃºltiplos modelos
4. **Contrastive Learning**: SimCLR, MoCo para melhor embedding
5. **Arquiteturas alternativas**: EfficientNet, Vision Transformer

---

## ğŸ› ï¸ Tecnologias

### Machine Learning
- **TensorFlow 2.x**: Framework principal
- **Keras**: API de alto nÃ­vel
- **MobileNetV2**: Arquitetura base (Transfer Learning)
- **NumPy**: ComputaÃ§Ã£o numÃ©rica
- **OpenCV**: Processamento de imagens
- **scikit-learn**: Split de dados

### Web Interface
- **Streamlit**: Framework web interativo
- **streamlit-drawable-canvas**: Canvas de desenho
- **Pillow**: ManipulaÃ§Ã£o de imagens
- **Requests**: Consultas Ã  PokeAPI

### Data Processing
- **Pandas**: (se usado para anÃ¡lise)
- **Matplotlib**: VisualizaÃ§Ã£o de grÃ¡ficos
- **PokeAPI**: Fonte de sprites oficiais

---

## ğŸ‘¨â€ğŸ’» Autor

**Thiago**

[![GitHub](https://img.shields.io/badge/GitHub-skaduhs5232-181717?style=flat&logo=github)](https://github.com/skaduhs5232)

---

## ğŸ“„ LicenÃ§a

Este projeto Ã© open source e estÃ¡ disponÃ­vel sob a licenÃ§a MIT.

---

## ğŸ™ Agradecimentos

- **PokeAPI**: Por fornecer sprites oficiais dos PokÃ©mon
- **TensorFlow/Keras**: Framework de Deep Learning
- **Streamlit**: Framework web rÃ¡pido e intuitivo
- **Comunidade PokÃ©mon**: Por inspirar este projeto

---

## ğŸ“š ReferÃªncias

- [MobileNetV2 Paper](https://arxiv.org/abs/1801.04381)
- [Transfer Learning Guide](https://www.tensorflow.org/tutorials/images/transfer_learning)
- [PokeAPI Documentation](https://pokeapi.co/)
- [Streamlit Documentation](https://docs.streamlit.io/)

---

**Feito com â¤ï¸ e TensorFlow**
